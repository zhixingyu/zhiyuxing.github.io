---
permalink: /
title: "Yuxing Zhi"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I'm a third year Doctoral student from School of Computer science and engineering, [Xi'an university of technology](https://www.xaut.edu.cn/). 

My research interest includes multimodal fusion, affective computing, and machine learning.

I am very fortunate to be advised by [Prof. Junhuai Li](https://scholar.google.com/citations?user=TJNhQfgAAAAJ&hl=zh-CN) from School of Computer Science and engineering.


Publications
======
\[1\]**Yuxing Zhi**, Junhuai Li, Huaijun Wang, Jing Chen and Wei Wei, "A Multimodal Sentiment Analysis Approach Based on Multi-view Cross-modal Fusion," IEEE Transactions on Computational Social Systems(JCR Q1, CCF C), 2025, Early access.[link](https://ieeexplore.ieee.org/document/11083650).

\[2\]**Yuxing Zhi**, Junhuai Li, Huaijun Wang, Jing Chen and Ting Cao, "A Fine-Grained Tri-Modal Interaction Model for Multimodal Sentiment Analysis," ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (CCF B). [Link](https://ieeexplore.ieee.org/document/10447872). 

\[3\]**Yuxing Zhi**, Junhuai Li, Huaijun Wang, Jing Chen and Wei. Wei, "A Multimodal Sentiment Analysis Method Based on Fuzzy Attention Fusion,"  IEEE Transactions on Fuzzy Systems (JCR Q1, CCF B, IF=11.9), 2024. [link](https://ieeexplore.ieee.org/document/10613477).

\[4\]Yue Li, **Yuxing Zhi**, Huai Wang, Yufan Guo, Kan Wang, Rong Fei and Junhuai Li. "Cross-domain human activity recognition based on deviation-graph constrained Non-Negative Matrix Factorization," Engineering Applications of Artificial Intelligence(JCR Q1, IF=8.0), 2025. [link](https://www.sciencedirect.com/science/article/pii/S095219762500661X)

\[5\]Li Junhuai, Cao Jingyi, **Yuxing Zhi**, Huaijun Wang and Fei Rong, "Cross-Domain Activity Recognition Based on Stacked Transfer Network," 2024 International Joint Conference on Neural Networks (IJCNN) (CCF C). [link](https://ieeexplore.ieee.org/document/10651514)

\[6\]Junhuai Li, Chuang Lin, Huaijun Wang, **Yuxing Zhi**, Jing Chen and Tao Huang, "Adversarial Training and Cross-modal Feature Fusion in Multimodal Sentiment Analysis," ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (CCF B), 2025. [link](https://ieeexplore.ieee.org/document/10890023)

Projects
======
1. **Emotionally Interactive Companion Based on Large Language Models**
   
   We are developing an AI-powered companion assistant that integrates **deep emotional understanding** and **personalized interaction capabilities**. Leveraging **multimodal emotion recognition technology** under both **full-modality and modality-missing scenarios**, this assistant accurately captures users' emotional states and feeds this information in real-time to a **Large Language Model (LLM)**. This process activates the LLM to generate **highly empathetic textual responses**. The system thereby delivers **real-time, personalized emotional support** and **social companionship** to users, effectively alleviating loneliness and enhancing their **psychological well-being**.
     
3. **Action Recognition for Children**

  We focus on **cross-domain child action analysis** and **multimodal recognition algorithm development**. Through **video capture**, **posture parsing**, and **motion trajectory modeling**, we establish a **high-precision action assessment framework** that enables real-time analysis of physical test movements and **quantifies children's developmental capabilities**. An **emotionally interactive auxiliary module** dynamically optimizes **human-machine interface interactions**, easing children's anxiety to ensure **natural and fluid testing procedures**. Our solution achieves **full-cycle management** of action recognition, performance evaluation, and training intervention, significantly enhancing the **scientific rigor** and **timeliness** of children's motor development.

